
# Setup
```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load libaries
library(openxlsx)
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(pROC)
library(gbm)
library(randomForest)
library(MASS)
library(performanceEstimation)
library(class)
library(boot)
library(glmnet)

# Set seed
set.seed(123)

results <- data.frame(
  Model = character(),
  Accuracy = numeric(),
  Precision = numeric(),
  Recall = numeric(),
  AOC = numeric(),
  stringsAsFactors = FALSE
)

# Define theme colors
primary_color = "#191919ff"
secondary_color = "#c67812ff"
```

# Load the data
```{r data_loading}
train_set <- read_excel("../data/hotel_data_balanced_train.xlsx")
test_set <- read_excel("../data/hotel_data_balanced_test.xlsx")

# Factorizing and normalizing
numerical_names <- c(
  "LeadTime", 
  "PreviousBookingsNotCanceled", 
  "StaysInWeekendNights", 
  "StaysInWeekNights", 
  "Adults", 
  "Children", 
  "Babies", 
  "BookingChanges", 
  "DaysInWaitingList",
  "TotalOfSpecialRequests"
)

train_set_numerical <- train_set %>% dplyr::select(numerical_names)
train_set_categorical <- train_set %>% dplyr::select(-one_of(numerical_names))

test_set_numerical <- test_set %>% dplyr::select(numerical_names)
test_set_categorical <- test_set %>% dplyr::select(-one_of(numerical_names))

# Factorize everything except for the LeadTime and PreviousCancellations variables
# Use a loop
for (i in 1:ncol(train_set_categorical)) {
  train_set_categorical[[i]] <- as.factor(train_set_categorical[[i]])
}

for (i in 1:ncol(train_set_categorical)) {
  test_set_categorical[[i]] <- as.factor(test_set_categorical[[i]])
}


# Normalize the numerical variables
train_set_numerical <- scale(train_set_numerical)
test_set_numerical <- scale(test_set_numerical)

# Merge data back together
train_set <- cbind(train_set_numerical, train_set_categorical)
test_set <- cbind(test_set_numerical, test_set_categorical)

class_balance <- prop.table(table(train_set$IsCanceled))
threshold <- class_balance[2]
```

# Random Forest Baseline
```{r random_forest_baseline}

set.seed(123)

# Random Forest
# We will use the randomForest function from the randomForest package to perform random forest classification

# 2. Fit the random forest model
rf_model <- randomForest(IsCanceled ~ ., data = train_set, ntree = 100, importance = TRUE)

# 3. Predictions
# Predictions on the testing set
p_hat <- predict(rf_model, newdata = test_set, type = "prob")
y_hat <- ifelse(p_hat[, 2] > threshold, 1, 0)

# Confusion matrix
confusion_matrix <- table(test_set$IsCanceled, y_hat)
confusion_matrix

# Accuracy, Precision, and Recall
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])

cat("Accuracy", accuracy, "\n")
cat("Precision: ", precision, "\n")
cat("Recall: ", recall, "\n")

# Generate AOC curve
roc_curve <- roc(test_set$IsCanceled, p_hat[,2])
aoc <- auc(roc_curve)
aoc

p <- ggroc(
  roc_curve, 
  col = secondary_color,
  lwd = 2,
) +
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color="grey", linetype="dashed") +
  theme(panel.background = element_rect(fill = "transparent")) +
  theme_minimal() +
  # Add AUC to the plot
  annotate(
    "text",
    x = 0.8,
    y = 1,
    label = paste("AUC:", round(aoc, 2)),
    size = 5,
    color = secondary_color
  )

p

ggsave(
  plot = p,
  filename = "./plots/modeling_random_forest_roc.png",
  bg = "transparent"
)

# Add to results
results <- rbind(
  results,
  data.frame(
    Model = "Random Forest",
    Accuracy = round(accuracy, 3),
    Precision = round(precision, 3),
    Recall = round(recall, 3),
    AOC = round(aoc, 3)
  )
)
```

# Random Forest Hyperparameter Tuning
```{r random_forest_hyperparameter_tuning}

# Define the cross-validation method
train_control <- trainControl(method = "repeatedcv",
                              number = 4,
                              repeats = 1,
                              search = "grid")

# Define the hyperparameter grid
tuning_grid <- expand.grid(.mtry = c(2, 5, 10),
                           .splitrule = c("gini"),
                           .min.node.size = c(1, 5, 10))

# Fit the random forest model
rf_model_tuned <- train(IsCanceled ~ .,
                        data = train_set,
                        method = "ranger",
                        trControl = train_control,
                        tuneGrid = tuning_grid,
                        importance = 'impurity',
                        metric = "Accuracy")

print(rf_model_tuned)

# 2. Fit the random forest model
rf_model <- randomForest(
  IsCanceled ~ ., 
  data = train_set, 
  mtry = 10,
  splitrule = "gini",
  min.node.size = 1,
)

# Predictions on the testing set
p_hat <- predict(rf_model, newdata = test_set, type = "prob")
y_hat <- ifelse(p_hat[, 2] > threshold, 1, 0)



# Confusion matrix
confusion_matrix <- table(test_set$IsCanceled, y_hat)
confusion_matrix

# Accuracy, Precision, and Recall
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])

cat("Accuracy", accuracy, "\n")
cat("Precision: ", precision, "\n")
cat("Recall: ", recall, "\n")

# Generate AOC curve
roc_curve <- roc(test_set$IsCanceled, p_hat[,2])
aoc <- auc(roc_curve)
aoc

p <- ggroc(
  roc_curve, 
  col = secondary_color,
  lwd = 2,
) +
  geom_segment(aes(x = 1, xend = 0, y = 0), color="grey", linetype="dashed") +
  theme(panel.background = element_rect(fill = "transparent")) +
  theme_minimal() +
  # Add AUC to the plot
  annotate(
    "text",
    x = 0.8,
    y = 1,
    label = paste("AUC:", round(aoc, 2)),
    size = 5,
    color = secondary_color
  )

p

ggsave(
  plot = p,
  filename = "./plots/modeling_random_forest_hyperparameter_tuning_roc.png",
  bg = "transparent"
)
```
